### Import Models

```py
import torch
from torch import nn, optim
from torchsummary import summary
from torchvision import transforms
from torch.utils.data import DataLoader
from torchvision.datasets import CIFAR10

from datetime import datetime
import matplotlib.pyplot as plt
```

### Transform

Using `torchvision.transforms` to preprocesse the CIFAR10 images.

```py
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize([0.5, 0.5, 0.5], [0.2, 0.2, 0.2])
])
```

### Dataset

Using `torchvision.datasets.CIFAR10` to download the dataset.

```py
train_ds = CIFAR10(
    root='./dataset/',
    train=True,
    download=True,
    transform=transform
)

test_ds = CIFAR10(
    root='./dataset/',
    train=False,
    download=True,
    transform=transform
)
```

### Image Shape

```py
train_ds[100][0].shape
```

### CUDA

Using `CUDA` to speed up the training process.

```py
if torch.cuda.is_available(): device = torch.device('cuda')
else: print('CUDA is not available.')
```

### CNN Model

```py
class CNN(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.conv1 = self.conv(3, 96)
        self.conv2 = self.conv(96, 256)
        self.conv3 = self.conv(256, 384)
        self.conv4 = self.conv(384, 256)

        self.linear1 = nn.Linear(2 * 2 * 256, 4096)
        self.linear2 = nn.Linear(4096, 2048)
        self.linear3 = nn.Linear(2048, 10)

        self.relu = nn.ReLU()
        self.flatten = nn.Flatten()
        self.dropout = nn.Dropout(0.5)

    def conv(self, inputs, outputs, kernel_size=3, padding=1) -> None:
        return nn.Sequential(
            nn.Conv2d(inputs, outputs, kernel_size=kernel_size, padding=padding),
            nn.BatchNorm2d(outputs),
            nn.ReLU(),
            nn.MaxPool2d(2)
        ).to(device=device)

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        x = self.conv1(x)
        x = self.conv2(x)
        x = self.conv3(x)
        x = self.conv4(x)

        x = self.flatten(x)

        x = self.linear1(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.linear2(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.linear3(x)

        return x
```

Then instantiate the model.

```py
model = CNN().to(device=device)
```

### Optimizer

```py
optimizer = optim.SGD(model.parameters(), lr=1e-1, weight_decay=0.001)
```

### Loss Function

```py
lossFunction = nn.CrossEntropyLoss()
```

### Data Loader

```py
train_dl = DataLoader(train_ds, batch_size=64, shuffle=True, num_workers=2, pin_memory=True)
test_dl = DataLoader(test_ds, batch_size=64, shuffle=True, num_workers=2, pin_memory=True)
```

### Model Summary

Now you can use the `torchsummary.summary()` function to check the summary.

```py
summary(model, (3, 32, 32))
```

```
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 96, 32, 32]           2,688
       BatchNorm2d-2           [-1, 96, 32, 32]             192
              ReLU-3           [-1, 96, 32, 32]               0
         MaxPool2d-4           [-1, 96, 16, 16]               0
            Conv2d-5          [-1, 256, 16, 16]         221,440
       BatchNorm2d-6          [-1, 256, 16, 16]             512
              ReLU-7          [-1, 256, 16, 16]               0
         MaxPool2d-8            [-1, 256, 8, 8]               0
            Conv2d-9            [-1, 384, 8, 8]         885,120
      BatchNorm2d-10            [-1, 384, 8, 8]             768
             ReLU-11            [-1, 384, 8, 8]               0
        MaxPool2d-12            [-1, 384, 4, 4]               0
           Conv2d-13            [-1, 256, 4, 4]         884,992
      BatchNorm2d-14            [-1, 256, 4, 4]             512
             ReLU-15            [-1, 256, 4, 4]               0
        MaxPool2d-16            [-1, 256, 2, 2]               0
          Flatten-17                 [-1, 1024]               0
           Linear-18                 [-1, 4096]       4,198,400
             ReLU-19                 [-1, 4096]               0
          Dropout-20                 [-1, 4096]               0
           Linear-21                 [-1, 2048]       8,390,656
             ReLU-22                 [-1, 2048]               0
          Dropout-23                 [-1, 2048]               0
           Linear-24                   [-1, 10]          20,490
================================================================
Total params: 14,605,770
Trainable params: 14,605,770
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 4.92
Params size (MB): 55.72
Estimated Total Size (MB): 60.65
----------------------------------------------------------------
```

### Validation Function

```py
@torch.no_grad()
def validate(model: CNN, dataloader: DataLoader) -> None:
    validate_accuracy, validate_total, validate_process, validate_time = 0, 0, 0, datetime.now().timestamp()

    for imgs, labels in dataloader:
        imgs: torch.Tensor
        labels: torch.Tensor

        imgs = imgs.to(device=device)
        labels = labels.to(device=device)

        outputs: torch.Tensor = model(imgs)

        _, predict = torch.max(outputs, 1)
        validate_accuracy += int((predict == labels).sum())
        validate_process += 1
        validate_total += labels.shape[0]

        dot = int(datetime.now().timestamp() - validate_time) % 4
        print(f'Validating{"." * dot + " " * (4 - dot)}{validate_process / len(dataloader) * 100:.2f}', end='\r')

    print(f'Validation Accuracy {validate_accuracy / validate_total * 100:.2f}%')
```

### Training Function

```py
def train(epochs: int, model: CNN, optimizer: optim.SGD, lossFunction: nn.CrossEntropyLoss, dataloader: DataLoader) -> None:
    for epoch in range(1, epochs + 1):
        train_accuracy, train_loss, train_total, train_process, train_time = 0, 0, 0, 0, datetime.now().timestamp()

        for imgs, labels in dataloader:
            imgs: torch.Tensor
            labels: torch.Tensor

            imgs = imgs.to(device=device)
            labels = labels.to(device=device)

            outputs: torch.Tensor = model(imgs)
            loss: torch.Tensor = lossFunction(outputs, labels)

            # optimizer.zero_grad()
            for param in model.parameters(): param.grad = None
            loss.backward()
            optimizer.step()

            _, predict = torch.max(outputs, 1)
            train_accuracy += int((predict == labels).sum())
            train_loss += loss.item()
            train_total += labels.shape[0]
            train_process += 1

            print(f'{datetime.now().strftime("%Y/%m/%d %H:%M:%S")} \
Epoch {epoch:03d} \
Time {datetime.now().timestamp() - train_time:.3f} \
Process {train_process / len(dataloader) * 100:.2f}% \
Accuracy {train_accuracy / train_total * 100:.2f}% \
Loss {train_loss / len(dataloader):.5f}', end='\r')

        print()
        validate(model, test_dl)
```

### Training

```py
train(epochs=10, model=model, optimizer=optimizer, lossFunction=lossFunction, dataloader=train_dl)
```

```
2023/06/17 18:42:05 Epoch 001 Time 15.304 Process 100.00% Accuracy 51.38% Loss 1.33795
Validation Accuracy 51.85%
2023/06/17 18:42:23 Epoch 002 Time 14.260 Process 100.00% Accuracy 68.22% Loss 0.91220
Validation Accuracy 57.94%
2023/06/17 18:42:41 Epoch 003 Time 14.254 Process 100.00% Accuracy 74.63% Loss 0.73711
Validation Accuracy 66.36%
2023/06/17 18:42:59 Epoch 004 Time 14.109 Process 100.00% Accuracy 78.64% Loss 0.61932
Validation Accuracy 64.73%
2023/06/17 18:43:18 Epoch 005 Time 14.180 Process 100.00% Accuracy 81.75% Loss 0.53348
Validation Accuracy 72.81%
2023/06/17 18:43:36 Epoch 006 Time 14.205 Process 100.00% Accuracy 84.13% Loss 0.45911
Validation Accuracy 70.17%
2023/06/17 18:43:54 Epoch 007 Time 14.193 Process 100.00% Accuracy 86.78% Loss 0.38655
Validation Accuracy 65.90%
2023/06/17 18:44:12 Epoch 008 Time 14.192 Process 100.00% Accuracy 88.56% Loss 0.33307
Validation Accuracy 78.65%
2023/06/17 18:44:30 Epoch 009 Time 14.187 Process 100.00% Accuracy 90.38% Loss 0.27952
Validation Accuracy 78.42%
2023/06/17 18:44:49 Epoch 010 Time 14.290 Process 100.00% Accuracy 91.74% Loss 0.24049
Validation Accuracy 85.59%
```