### Import Models

```py
import torch
from torch import nn, optim
from torchsummary import summary
from torchvision import transforms
from torch.utils.data import DataLoader
from torchvision.datasets import CIFAR10

from datetime import datetime
import matplotlib.pyplot as plt
```

### Transform

Using `torchvision.transforms` to preprocesse the CIFAR10 images.

```py
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize([0.5, 0.5, 0.5], [0.2, 0.2, 0.2])
])
```

### Dataset

Using `torchvision.datasets.CIFAR10` to download the dataset.

```py
train_ds = CIFAR10(
    root='./dataset/',
    train=True,
    download=True,
    transform=transform
)

test_ds = CIFAR10(
    root='./dataset/',
    train=False,
    download=True,
    transform=transform
)
```

### Data Loader

```py
train_dl = DataLoader(train_ds, batch_size=64, shuffle=True, num_workers=2, pin_memory=True)
test_dl = DataLoader(test_ds, batch_size=64, shuffle=True, num_workers=2, pin_memory=True)
```

### Image Shape

```py
train_ds[100][0].shape
```

```
torch.Size([3, 32, 32])
```

### CUDA

Using `CUDA` to speed up the training process.

```py
if torch.cuda.is_available():
    print('CUDA is available.')
    device = torch.device('cuda')
else:
    print('CUDA is not available, use CPU instead.')
    device = torch.device('cpu')
```

### CNN Model

```py
class CNN(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.conv1 = self.conv(3, 96)
        self.conv2 = self.conv(96, 256)
        self.conv3 = self.conv(256, 384)
        self.conv4 = self.conv(384, 256)

        self.linear1 = nn.Linear(2 * 2 * 256, 4096)
        self.linear2 = nn.Linear(4096, 2048)
        self.linear3 = nn.Linear(2048, 10)

        self.relu = nn.ReLU()
        self.flatten = nn.Flatten()
        self.dropout = nn.Dropout(0.5)

    def conv(self, inputs, outputs, kernel_size=3, padding=1) -> None:
        return nn.Sequential(
            nn.Conv2d(inputs, outputs, kernel_size=kernel_size, padding=padding),
            nn.BatchNorm2d(outputs),
            nn.ReLU(),
            nn.MaxPool2d(2)
        ).to(device=device)

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        x = self.conv1(x)
        x = self.conv2(x)
        x = self.conv3(x)
        x = self.conv4(x)

        x = self.flatten(x)

        x = self.linear1(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.linear2(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.linear3(x)

        return x
```

Then instantiate the model.

```py
model = CNN().to(device=device)
```

### Optimizer

```py
optimizer = optim.SGD(model.parameters(), lr=1e-1, weight_decay=0.001)
```

### Loss Function

```py
lossFunction = nn.CrossEntropyLoss()
```

### Model Summary

Now you can use the `torchsummary.summary()` function to check the summary.

```py
summary(model, (3, 32, 32))
```

```
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
├─Sequential: 1-1                        [-1, 96, 16, 16]          --
|    └─Conv2d: 2-1                       [-1, 96, 32, 32]          2,688
|    └─BatchNorm2d: 2-2                  [-1, 96, 32, 32]          192
|    └─ReLU: 2-3                         [-1, 96, 32, 32]          --
|    └─MaxPool2d: 2-4                    [-1, 96, 16, 16]          --
├─Sequential: 1-2                        [-1, 256, 8, 8]           --
|    └─Conv2d: 2-5                       [-1, 256, 16, 16]         221,440
|    └─BatchNorm2d: 2-6                  [-1, 256, 16, 16]         512
|    └─ReLU: 2-7                         [-1, 256, 16, 16]         --
|    └─MaxPool2d: 2-8                    [-1, 256, 8, 8]           --
├─Sequential: 1-3                        [-1, 384, 4, 4]           --
|    └─Conv2d: 2-9                       [-1, 384, 8, 8]           885,120
|    └─BatchNorm2d: 2-10                 [-1, 384, 8, 8]           768
|    └─ReLU: 2-11                        [-1, 384, 8, 8]           --
|    └─MaxPool2d: 2-12                   [-1, 384, 4, 4]           --
├─Sequential: 1-4                        [-1, 256, 2, 2]           --
|    └─Conv2d: 2-13                      [-1, 256, 4, 4]           884,992
|    └─BatchNorm2d: 2-14                 [-1, 256, 4, 4]           512
|    └─ReLU: 2-15                        [-1, 256, 4, 4]           --
|    └─MaxPool2d: 2-16                   [-1, 256, 2, 2]           --
├─Flatten: 1-5                           [-1, 1024]                --
├─Linear: 1-6                            [-1, 4096]                4,198,400
├─ReLU: 1-7                              [-1, 4096]                --
├─Dropout: 1-8                           [-1, 4096]                --
├─Linear: 1-9                            [-1, 2048]                8,390,656
├─ReLU: 1-10                             [-1, 2048]                --
├─Dropout: 1-11                          [-1, 2048]                --
├─Linear: 1-12                           [-1, 10]                  20,490
==========================================================================================
Total params: 14,605,770
Trainable params: 14,605,770
Non-trainable params: 0
Total mult-adds (M): 144.65
==========================================================================================
Input size (MB): 0.01
Forward/backward pass size (MB): 2.98
Params size (MB): 55.72
Estimated Total Size (MB): 58.71
==========================================================================================
```

### Validation Function

```py
@torch.no_grad()
def validate(model: CNN, dataloader: DataLoader) -> None:
    validate_total = 0
    validate_process = 0
    validate_accuracy = 0
    validate_time = datetime.now().timestamp()

    for imgs, labels in dataloader:
        imgs: torch.Tensor
        labels: torch.Tensor

        imgs = imgs.to(device=device)
        labels = labels.to(device=device)

        outputs: torch.Tensor = model(imgs)

        _, predict = torch.max(outputs, 1)
        validate_accuracy += int((predict == labels).sum())
        validate_process += 1
        validate_total += labels.shape[0]

        dot = int(datetime.now().timestamp() - validate_time) % 4
        print(f'Validating{"." * dot + " " * (4 - dot)}{validate_process / len(dataloader) * 100:.2f}', end='\r')

    print(f'Validation Accuracy {validate_accuracy / validate_total * 100:.2f}%')
```

### Training Function

```py
def train(epochs: int, model: CNN, optimizer: optim.SGD, lossFunction: nn.CrossEntropyLoss, dataloader: DataLoader) -> None:
    for epoch in range(1, epochs + 1):
        train_loss = 0
        train_total = 0
        train_process = 0
        train_accuracy = 0
        train_time = datetime.now().timestamp()

        for imgs, labels in dataloader:
            imgs: torch.Tensor
            labels: torch.Tensor

            imgs = imgs.to(device=device)
            labels = labels.to(device=device)

            outputs: torch.Tensor = model(imgs)
            loss: torch.Tensor = lossFunction(outputs, labels)

            # optimizer.zero_grad()
            for param in model.parameters(): param.grad = None
            loss.backward()
            optimizer.step()

            _, predict = torch.max(outputs, 1)
            train_accuracy += int((predict == labels).sum())
            train_loss += loss.item()
            train_total += labels.shape[0]
            train_process += 1

            print(f'{datetime.now().strftime("%Y/%m/%d %H:%M:%S")} \
Epoch {epoch:03d} \
Time {datetime.now().timestamp() - train_time:.3f} \
Process {train_process / len(dataloader) * 100:.2f}% \
Accuracy {train_accuracy / train_total * 100:.2f}% \
Loss {train_loss / len(dataloader):.5f}', end='\r')

        print()
        validate(model, test_dl)
```

### Training

```py
train(epochs=10, model=model, optimizer=optimizer, lossFunction=lossFunction, dataloader=train_dl)
```

```
2023/06/26 12:35:19 Epoch 001 Time 11.645 Process 100.00% Accuracy 51.14% Loss 1.34106
Validation Accuracy 42.46%
2023/06/26 12:35:29 Epoch 002 Time 7.098 Process 100.00% Accuracy 67.97% Loss 0.91723
Validation Accuracy 63.76%
2023/06/26 12:35:39 Epoch 003 Time 7.082 Process 100.00% Accuracy 74.13% Loss 0.74346
Validation Accuracy 72.35%
2023/06/26 12:35:49 Epoch 004 Time 6.923 Process 100.00% Accuracy 78.18% Loss 0.62850
Validation Accuracy 75.62%
2023/06/26 12:35:59 Epoch 005 Time 6.895 Process 100.00% Accuracy 81.52% Loss 0.53423
Validation Accuracy 70.35%
2023/06/26 12:36:09 Epoch 006 Time 6.899 Process 100.00% Accuracy 83.95% Loss 0.46433
Validation Accuracy 78.93%
2023/06/26 12:36:18 Epoch 007 Time 7.003 Process 100.00% Accuracy 86.40% Loss 0.39620
Validation Accuracy 76.91%
2023/06/26 12:36:28 Epoch 008 Time 6.928 Process 100.00% Accuracy 88.37% Loss 0.33573
Validation Accuracy 77.30%
2023/06/26 12:36:38 Epoch 009 Time 6.976 Process 100.00% Accuracy 90.19% Loss 0.28335
Validation Accuracy 78.93%
2023/06/26 12:36:48 Epoch 010 Time 7.023 Process 100.00% Accuracy 91.63% Loss 0.23983
Validation Accuracy 80.81%
```
## References

<ul class="public-article-references">
    <li>【 PyTorch】CIFAR-10の画像分類, Qiita - <a href="https://qiita.com/mako0715/items/0c9499a7dc124d6d2f40" target="_blank">https://qiita.com/mako0715/items/0c9499a7dc124d6d2f40</a>
    </li><li>CIFAR10, Pytorch - <a href="https://pytorch.org/vision/stable/generated/torchvision.datasets.CIFAR10.html" target="_blank">https://pytorch.org/vision/stable/generated/torchvision.datasets.CIFAR10.html</a></li>
</ul>